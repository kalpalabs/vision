{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "cifar10_classes = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}\n",
    "\n",
    "cifar10_class_to_idx = {v: k for k, v in cifar10_classes.items()}\n",
    "\n",
    "label_transform = lambda label: cifar10_classes[label]\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root='/home/azureuser/gautijha37/vision/data',      # Directory where the data will be stored/loaded from\n",
    "    train=True,        # Load the training set\n",
    "    download=True,     # Download the dataset if it's not already present\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
    "                         std=(0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "    target_transform=label_transform   \n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Use random_split to safely create subsets\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/gautijha37/vision/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import SiglipModel, SiglipImageProcessor, SiglipTokenizer, SiglipConfig\n",
    "\n",
    "config = SiglipConfig()\n",
    "config.vision_config.image_size=32\n",
    "config.text_config.max_position_embeddings=4 # max length of tokenized classes\n",
    "\n",
    "config.text_config.num_hidden_layers=3 # using all 12 sees 4% accuracy increase.\n",
    "config.vision_config.num_hidden_layers=3\n",
    "\n",
    "model = SiglipModel(config).to(device)\n",
    "\n",
    "img_processor = SiglipImageProcessor(do_resize=False, do_rescale=False) # transforms.ToTensor() already scales input img to [-1, 1]\n",
    "tokenizer = SiglipTokenizer.from_pretrained(\"google/siglip-base-patch16-224\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters()) // 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def accuracy(model, tokenizer, data_loader):\n",
    "    correct = 0\n",
    "    all_text_inputs = list(cifar10_classes.values())\n",
    "    text_inputs = tokenizer(text=all_text_inputs, padding=True, return_tensors=\"pt\")\n",
    "    text_inputs['input_ids']=text_inputs['input_ids'].to(device)\n",
    "\n",
    "    for img_inputs, _, _, correct_labels in tqdm(data_loader):\n",
    "        img_inputs['pixel_values']=img_inputs['pixel_values'].to(device)\n",
    "        \n",
    "        output = model(**text_inputs, **img_inputs)\n",
    "        predicted_indices = output.logits_per_image.argmax(dim=1)\n",
    "        predicted_labels = [cifar10_classes[k.item()] for k in predicted_indices]\n",
    "        \n",
    "        correct += sum(p == c for p, c in zip(predicted_labels, list(correct_labels)))\n",
    "\n",
    "    total = len(data_loader) * data_loader.batch_size\n",
    "    return 100 * correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgauti-jha37\u001b[0m (\u001b[33mgauti-jha37-personal\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/azureuser/gautijha37/vision/starterprojects/gautijha37/wandb/run-20250307_140654-iiudq28f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gauti-jha37-personal/siglip-cifar10/runs/iiudq28f' target=\"_blank\">upbeat-deluge-17</a></strong> to <a href='https://wandb.ai/gauti-jha37-personal/siglip-cifar10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gauti-jha37-personal/siglip-cifar10' target=\"_blank\">https://wandb.ai/gauti-jha37-personal/siglip-cifar10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gauti-jha37-personal/siglip-cifar10/runs/iiudq28f' target=\"_blank\">https://wandb.ai/gauti-jha37-personal/siglip-cifar10/runs/iiudq28f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], train_loss: 26.0088, val_loss: 26.1353, val_accuracy: 9.8627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.59it/s]\n",
      "  4%|▍         | 2/50 [00:30<12:13, 15.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], train_loss: 25.1383, val_loss: 25.2227, val_accuracy: 11.0768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.82it/s]\n",
      "  6%|▌         | 3/50 [00:46<12:02, 15.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], train_loss: 24.4650, val_loss: 24.5965, val_accuracy: 9.8029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.47it/s]\n",
      "  8%|▊         | 4/50 [01:01<11:39, 15.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], train_loss: 25.1556, val_loss: 23.8149, val_accuracy: 13.7938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.91it/s]\n",
      " 10%|█         | 5/50 [01:16<11:26, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], train_loss: 23.3216, val_loss: 23.3786, val_accuracy: 12.2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.94it/s]\n",
      " 12%|█▏        | 6/50 [01:32<11:15, 15.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], train_loss: 23.4012, val_loss: 23.2427, val_accuracy: 16.2719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.64it/s]\n",
      " 14%|█▍        | 7/50 [01:47<11:02, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], train_loss: 23.5171, val_loss: 22.7798, val_accuracy: 16.9686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 102.68it/s]\n",
      " 16%|█▌        | 8/50 [02:03<10:51, 15.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], train_loss: 22.2421, val_loss: 22.5570, val_accuracy: 11.1664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.54it/s]\n",
      " 18%|█▊        | 9/50 [02:18<10:33, 15.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], train_loss: 21.9588, val_loss: 22.6275, val_accuracy: 14.6596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.95it/s]\n",
      " 20%|██        | 10/50 [02:34<10:17, 15.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], train_loss: 21.9991, val_loss: 22.2400, val_accuracy: 16.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.53it/s]\n",
      " 22%|██▏       | 11/50 [02:49<09:56, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], train_loss: 20.8036, val_loss: 21.6226, val_accuracy: 18.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.64it/s]\n",
      " 24%|██▍       | 12/50 [03:04<09:44, 15.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], train_loss: 22.2839, val_loss: 21.2578, val_accuracy: 17.9240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.44it/s]\n",
      " 26%|██▌       | 13/50 [03:19<09:24, 15.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], train_loss: 21.4356, val_loss: 20.9978, val_accuracy: 17.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 105.30it/s]\n",
      " 28%|██▊       | 14/50 [03:34<09:10, 15.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], train_loss: 21.9368, val_loss: 20.7510, val_accuracy: 18.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.16it/s]\n",
      " 30%|███       | 15/50 [03:50<08:56, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], train_loss: 20.5483, val_loss: 20.6277, val_accuracy: 18.5908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 106.05it/s]\n",
      " 32%|███▏      | 16/50 [04:05<08:42, 15.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], train_loss: 20.0663, val_loss: 20.5129, val_accuracy: 20.4717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 102.87it/s]\n",
      " 34%|███▍      | 17/50 [04:21<08:27, 15.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], train_loss: 20.1625, val_loss: 20.0411, val_accuracy: 24.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.08it/s]\n",
      " 36%|███▌      | 18/50 [04:36<08:14, 15.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], train_loss: 19.2837, val_loss: 19.4839, val_accuracy: 29.7771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.50it/s]\n",
      " 38%|███▊      | 19/50 [04:52<07:59, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], train_loss: 19.2164, val_loss: 19.2899, val_accuracy: 30.0756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.54it/s]\n",
      " 40%|████      | 20/50 [05:07<07:43, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], train_loss: 22.1218, val_loss: 19.1033, val_accuracy: 32.3746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.75it/s]\n",
      " 42%|████▏     | 21/50 [05:23<07:29, 15.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], train_loss: 20.5284, val_loss: 18.8708, val_accuracy: 33.6584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.88it/s]\n",
      " 44%|████▍     | 22/50 [05:38<07:14, 15.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], train_loss: 18.7551, val_loss: 18.4695, val_accuracy: 34.5840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.92it/s]\n",
      " 46%|████▌     | 23/50 [05:54<06:58, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], train_loss: 17.9504, val_loss: 18.3148, val_accuracy: 37.1915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.71it/s]\n",
      " 48%|████▊     | 24/50 [06:09<06:43, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], train_loss: 15.7095, val_loss: 18.2777, val_accuracy: 37.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.13it/s]\n",
      " 50%|█████     | 25/50 [06:25<06:26, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], train_loss: 16.4187, val_loss: 17.8142, val_accuracy: 40.1473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.17it/s]\n",
      " 52%|█████▏    | 26/50 [06:40<06:11, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], train_loss: 17.1085, val_loss: 17.6667, val_accuracy: 39.8288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.98it/s]\n",
      " 54%|█████▍    | 27/50 [06:56<05:55, 15.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], train_loss: 15.5486, val_loss: 17.7487, val_accuracy: 39.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 102.34it/s]\n",
      " 56%|█████▌    | 28/50 [07:11<05:39, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], train_loss: 16.8219, val_loss: 17.4909, val_accuracy: 41.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.61it/s]\n",
      " 58%|█████▊    | 29/50 [07:26<05:21, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], train_loss: 16.6237, val_loss: 17.3074, val_accuracy: 41.7994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.99it/s]\n",
      " 60%|██████    | 30/50 [07:41<05:06, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], train_loss: 13.2278, val_loss: 17.3827, val_accuracy: 42.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 105.09it/s]\n",
      " 62%|██████▏   | 31/50 [07:57<04:51, 15.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], train_loss: 13.4633, val_loss: 17.3114, val_accuracy: 41.8690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.17it/s]\n",
      " 64%|██████▍   | 32/50 [08:12<04:36, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], train_loss: 15.1591, val_loss: 17.2452, val_accuracy: 41.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.56it/s]\n",
      " 66%|██████▌   | 33/50 [08:28<04:21, 15.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], train_loss: 14.1658, val_loss: 17.3836, val_accuracy: 42.4861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.88it/s]\n",
      " 68%|██████▊   | 34/50 [08:43<04:04, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], train_loss: 14.1160, val_loss: 17.4987, val_accuracy: 41.7994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.58it/s]\n",
      " 70%|███████   | 35/50 [08:58<03:48, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], train_loss: 14.6254, val_loss: 17.5311, val_accuracy: 42.1576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.48it/s]\n",
      " 72%|███████▏  | 36/50 [09:13<03:32, 15.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], train_loss: 12.4944, val_loss: 17.5681, val_accuracy: 42.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 105.13it/s]\n",
      " 74%|███████▍  | 37/50 [09:29<03:19, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], train_loss: 11.0346, val_loss: 17.6050, val_accuracy: 42.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 102.78it/s]\n",
      " 76%|███████▌  | 38/50 [09:44<03:02, 15.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], train_loss: 10.6454, val_loss: 17.8368, val_accuracy: 42.2671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.93it/s]\n",
      " 78%|███████▊  | 39/50 [09:59<02:48, 15.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], train_loss: 10.6916, val_loss: 18.0355, val_accuracy: 42.1975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.62it/s]\n",
      " 80%|████████  | 40/50 [10:14<02:31, 15.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], train_loss: 12.2909, val_loss: 17.9816, val_accuracy: 42.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.33it/s]\n",
      " 82%|████████▏ | 41/50 [10:29<02:17, 15.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], train_loss: 11.0858, val_loss: 17.9350, val_accuracy: 42.1676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.46it/s]\n",
      " 84%|████████▍ | 42/50 [10:45<02:02, 15.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], train_loss: 11.7832, val_loss: 18.0157, val_accuracy: 42.2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.66it/s]\n",
      " 86%|████████▌ | 43/50 [11:00<01:47, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], train_loss: 10.3816, val_loss: 18.2915, val_accuracy: 42.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 105.06it/s]\n",
      " 88%|████████▊ | 44/50 [11:15<01:31, 15.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], train_loss: 10.0250, val_loss: 18.4042, val_accuracy: 42.0482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.28it/s]\n",
      " 90%|█████████ | 45/50 [11:31<01:16, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], train_loss: 10.1612, val_loss: 18.3246, val_accuracy: 42.1079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.73it/s]\n",
      " 92%|█████████▏| 46/50 [11:47<01:01, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], train_loss: 10.7350, val_loss: 18.4070, val_accuracy: 42.1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.54it/s]\n",
      " 94%|█████████▍| 47/50 [12:02<00:45, 15.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], train_loss: 10.7656, val_loss: 18.4504, val_accuracy: 41.7795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 102.80it/s]\n",
      " 96%|█████████▌| 48/50 [12:17<00:30, 15.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], train_loss: 9.6865, val_loss: 18.4388, val_accuracy: 42.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 103.36it/s]\n",
      " 98%|█████████▊| 49/50 [12:32<00:15, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], train_loss: 10.5721, val_loss: 18.4961, val_accuracy: 41.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 104.87it/s]\n",
      "100%|██████████| 50/50 [12:47<00:00, 15.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], train_loss: 11.3788, val_loss: 18.5073, val_accuracy: 41.8690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import wandb\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "lr = 1e-4\n",
    "\n",
    "wandb.init(project=\"siglip-cifar10\", config={\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": lr,\n",
    "    \"model\": \"SigLIP\",\n",
    "    \"dataset\": \"CIFAR10\",\n",
    "    \"num_hidden_layers\": config.text_config.num_hidden_layers,\n",
    "    \"image_size\": config.vision_config.image_size,\n",
    "    \"max_position_embeddings\": config.text_config.max_position_embeddings\n",
    "})\n",
    "\n",
    "# Dataloader\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    img_inputs = img_processor(images=images, return_tensors=\"pt\")\n",
    "    text_inputs = tokenizer(text = labels, padding=True, return_tensors=\"pt\")\n",
    "    \n",
    "    labels_ids = torch.tensor([cifar10_class_to_idx[label] for label in labels])\n",
    "    batch_mask = (labels_ids.unsqueeze(1) == labels_ids.unsqueeze(0)).float()\n",
    "    batch_mask = 2 * batch_mask - 1\n",
    "    \n",
    "    return img_inputs, text_inputs, batch_mask, labels\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=16, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=16, collate_fn=collate_fn)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=num_epochs,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# loss calculation\n",
    "def calculate_loss(model, batch):\n",
    "    img_inputs, text_inputs, batch_mask, _ = batch\n",
    "    img_inputs['pixel_values']=img_inputs['pixel_values'].to(device)\n",
    "    text_inputs['input_ids']=text_inputs['input_ids'].to(device)\n",
    "    batch_mask=batch_mask.to(device)\n",
    "    \n",
    "    # loss calculation\n",
    "    output = model(**text_inputs, **img_inputs)\n",
    "    loglik = torch.nn.functional.logsigmoid(batch_mask * output.logits_per_text)\n",
    "    nll = -torch.sum(loglik, dim=-1)\n",
    "    loss = nll.mean()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch_id, batch in enumerate(train_loader):\n",
    "        loss = calculate_loss(model, batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        wandb.log({\n",
    "            \"batch_loss\": loss.item(),\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            val_loss += calculate_loss(model, batch)\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = accuracy(model, tokenizer, val_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], train_loss: {loss:.4f}, val_loss: {val_loss:.4f}, val_accuracy: {val_accuracy:.4f}\")\n",
    "    wandb.log({\n",
    "        \"epoch_train_loss\": loss,\n",
    "        \"epoch_val_loss\": val_loss,\n",
    "        \"epoch_val_accuracy\": val_accuracy\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import save_file\n",
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, \"/home/azureuser/gautijha37/vision/siglip.safetensors6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 105.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.590366242038215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='/home/azureuser/gautijha37/vision/data',\n",
    "    train=False,        # Load the test set\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
    "                         std=(0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "    target_transform=label_transform\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=16, shuffle=True, collate_fn=collate_fn)\n",
    "print(accuracy(model, tokenizer, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
